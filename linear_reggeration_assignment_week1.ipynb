{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "3f9a4427-28e1-417e-88ee-616a8e447bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "2c2df221-a81d-4ed4-ad8b-6f3879a0bc4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel('E:/Training data.xlsx')\n",
    "x_train = np.array(data.iloc[:,0:8])\n",
    "y_train = np.array(data.iloc[:,8]).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "997161d8-6b3c-4344-85e5-434453cdbfa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_changing(x_train):\n",
    "  # ---------\n",
    "    # Your code here\n",
    "    x_train[:,0] = np.where((x_train[:,0] == 'yes'),1,0)\n",
    "    x_train[:,1] = np.where((x_train[:,1] == 'M'),1,0)\n",
    "    \n",
    "    \n",
    "  # ---------\n",
    "    return x_train\n",
    "\n",
    "x_train = feature_changing(x_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "e828d351-6d83-43fa-abf0-98c83cc854c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def z_score(x_train):\n",
    "\n",
    "  # ---------\n",
    "    # write the code for feature scaling here\n",
    "    # Your code here\n",
    "  # ---------\n",
    "    \n",
    "    x_mean = np.mean(x_train, axis = 0)\n",
    "    x_std = np.std(x_train, axis = 0)\n",
    "    x_train = (x_train-x_mean)/x_std\n",
    "    return x_train,x_std,x_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "ead00e29-9482-4dcd-b991-b26ce2ab72b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hypo(x_train,w,b):\n",
    "    return (np.dot(x_train,w)+b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "9fff2828-1bd7-4de0-a60a-a600be5a03c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost(x_train,y_train,w,b):\n",
    "\n",
    "  # ---------\n",
    "    # Your code here\n",
    "    # Use mean square error as cost function\n",
    "    # return cost\n",
    "  # ---------\n",
    "    y_pred = hypo(x_train,w,b)\n",
    "    loss = 0\n",
    "    loss = (y_pred - y_train)\n",
    "    \n",
    "    return np.mean(loss**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "4241fd61-926c-4f34-9176-cf629564f47c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient(x_train,y_train,w,b):\n",
    "    y_pred = hypo(x_train, w,b)\n",
    "    grad = np.dot(x_train.T,(y_pred-y_train))\n",
    "    grad_b = np.sum(y_pred-y_train)\n",
    "#for b \n",
    "    return grad/x_train.shape[0],grad_b/x_train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "f88d8f2f-06a2-47d4-905a-126a8b0e882f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(x_train,y_train,w,b):\n",
    "\n",
    "  # ---------\n",
    "    # Your code here\n",
    "    # Choose learning rate yourself\n",
    "  # ---------\n",
    "    lr_rate = 0.03\n",
    "    epochs = 100000\n",
    "  \n",
    "    loss_epoch = []\n",
    "\n",
    "    for i in range(epochs):\n",
    "        grad,grad_b = gradient(x_train, y_train, w,b)\n",
    "        loss_epoch.append(cost(x_train,y_train,w,b))\n",
    "        # lr_rate_new= lr_rate/ (1 + i * 0.001)\n",
    "        w= w- lr_rate * grad\n",
    "        b = b - lr_rate*grad_b\n",
    "\n",
    "    return w,b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "97298a39-6b63-48ca-8886-57a74add928f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Congratulations, your accuracy is 100.0%\n"
     ]
    }
   ],
   "source": [
    "x_train = x_train.astype(np.float64)\n",
    "x_train,x_std,x_mean = z_score(x_train)\n",
    "# y_train,y_std,y_mean = z_score(y_train)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "np.random.seed(2147483647)\n",
    "w = np.random.randn(x_train.shape[1],1)\n",
    "b = np.random.randn(1)\n",
    "\n",
    "old_cost = 0\n",
    "losses=[]\n",
    "while abs(old_cost - cost(x_train,y_train,w,b))>0.00001:\n",
    "    old_cost = cost(x_train,y_train,w,b)\n",
    "    \n",
    "    w,b = gradient_descent(x_train,y_train,w,b)\n",
    "\n",
    "x_predict = pd.read_excel('E:/Test data.xlsx').iloc[:,:8].to_numpy()\n",
    "x_predict = feature_changing(x_predict)\n",
    "x_predict = (x_predict - x_mean)/x_std\n",
    "ans = pd.read_excel('E:/Test data.xlsx').iloc[:,8].to_numpy()\n",
    "\n",
    "y_predict = np.dot(x_predict,w) + b\n",
    "\n",
    "accuracy = 0\n",
    "for dim in range(len(ans)):\n",
    "  if abs(y_predict[dim]-ans[dim])<0.5: # do not change the tolerance as you'll be checked on +- 0.5 error only\n",
    "    accuracy += 1\n",
    "accuracy = round(accuracy*100/200.0,2)\n",
    "ok = 'Congratulations' if accuracy>95 else 'Optimization required'\n",
    "print(f\"{ok}, your accuracy is {accuracy}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7adefb6-18e8-40db-b9cb-6fae668ccb9a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
